# PREREQUISITES:
# The following secrets must be stored in your repository where this Action runs:
# AWS_ACCESS_KEY_ID
# AWS_CLOUDFRONT_DISTRO_ID
# AWS_S3_BUCKET_NAME
# AWS_SECRET_ACCESS_KEY

name: CI
on:
  push:
    branches: 
    - master
  pull_request:
    branches: 
    - master
env:
  # Default AWS region where S3 pushes and CloudFront invalidations will occur.
  AWS-DEFAULT-REGION: us-east-2
  # Name of the branch in your repository which will store your generated site.
  SITE-BRANCH: site

jobs:
  build:
  # In this phase, the code is pulled from master and the site rendered in Hugo. The built site is stored as an artifact for other stages.
    runs-on: ubuntu-18.04
    steps:
    # Check out master branch from the repo.
    - name: Checkout master branch
      uses: actions/checkout@v2
      with:
        submodules: true  # Fetch Hugo themes
        fetch-depth: 0    # Fetch all history for .GitInfo and .Lastmod
        ref: master
    # Ensure the site succeeds Hugo builds. If it fails for some reason, the pipeline will halt.
    - name: Build site with Hugo
      uses: lowply/build-hugo@v0.69.0
    # If build succeeds, store the public/ dir as an artifact to be used in subsequent phases.
    - name: Upload output public dir as artifact
      uses: actions/upload-artifact@v1
      with:
        name: public
        path: public/
  publish:
  # In the publish phase, the site is pushed up to a different branch which only stores the public/ folder ("site" branch) and is also delta synchronized to the S3 bucket. CloudFront invalidation happens last.
    runs-on: ubuntu-18.04
    needs: build
    steps:
    # Check out the site branch this time since we have to ultimately commit those changes there.
    - name: Checkout site branch
      uses: actions/checkout@v2
      with:
        submodules: true
        fetch-depth: 0
        ref: ${{ env.SITE-BRANCH }}
    # Download the artifact containing the newly built site. This overwrites the public/ dir from the check out above.
    - name: Download artifact from build stage
      uses: actions/download-artifact@v1
      with:
        name: public
    # Add all the files/changes in public/ that were pulled down from the build stage and then commit them.
    # The final line sets a GitHub Action output value that can be read by other steps.
    # This function cannot store mult-line values so newline chars must be stripped.
    - name: Commit files
      id: can_commit
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -A public/
        commit_message=$(git commit -m "Publish generated Hugo site." -a | tr -d '\n' || true)
        echo "::set-output name=commit_message::$commit_message"
    # Checks if previous stage had any valid commit.
    - name: Nothing to commit
      id: nothing_committed
      if: contains(steps.can_commit.outputs.commit_message, 'nothing to commit')
      run: echo "Saw that no changes were made to Hugo site."
    # Push those changes back to the site branch.
    - name: Push to site branch
      if: steps.nothing_committed.conclusion == 'skipped'
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: ${{ env.SITE-BRANCH }}
    # Store the AWS credentials on the runner.
    - name: Configure AWS credentials
      if: steps.nothing_committed.conclusion == 'skipped'
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS-DEFAULT-REGION }}
    # Use s5cmd to perform only a delta sync to the destination S3 bucket. This minimizes transfer traffic since it only uploads changed files.
    - name: Delta sync site to S3 bucket
      if: steps.nothing_committed.conclusion == 'skipped'
      run: |
        curl -sLO https://github.com/peak/s5cmd/releases/download/v1.0.0/s5cmd_1.0.0_Linux-64bit.tar.gz
        tar -xzf s5cmd_1.0.0_Linux-64bit.tar.gz
        chmod +x s5cmd
        sudo mv s5cmd /usr/local/bin/
        echo "****Showing working dir and listing files.****"
        pwd && ls -lah
        echo "****Running delta sync against S3.****"
        s5cmd cp -s public/ s3://${{ secrets.AWS_S3_BUCKET_NAME }}
    # Use the aws cli tool to perform a glob invalidation of the entire site against CloudFront.
    - name: Invalidate cache on CloudFront
      if: steps.nothing_committed.conclusion == 'skipped'
      run: aws cloudfront create-invalidation --distribution-id ${{ secrets.AWS_CLOUDFRONT_DISTRO_ID }} --paths "/*"